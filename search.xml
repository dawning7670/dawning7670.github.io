<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CSAPP-存储器层次结构]]></title>
    <url>%2F2017%2F11%2F21%2FCSAPP-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[随机访问存储器 SRAM 存储在双稳态单元中，抗干扰能力强，一般用于高速缓存 DRAM 依赖电容存储，抗干扰能力弱，需要重写刷新来维持存储状态，一般用于内存 磁盘 机械存储结构，主要包括：扇区、磁道、盘片、主轴和磁头； 数据读取依赖主轴移动磁头在盘片上找到对应的磁道上的扇区； 顺序访问速度快，随机访问速度慢 固态硬盘 使用电路结构（闪存翻译层）代替机械结构做地址映射； 顺序和随机读都非常快，写性能则一般（可能需要擦除和移动块） 存储器层次结构 程序局部性原理从操作系统的存储器层次结构，到现在后端开发中应对高并发使用的缓存系统，都是因为程序的局部性 程序的局部性原理分两类 时间局部性 从时间的角度来说就是连续多次访问缓存中的元素 空间局部性 从空间的角度来说就是利用好缓存块，尽量访问某元素相邻元素 高速缓存基本概念 缓存命中：某次读或写操作刚好存储在当前层的缓存中 缓存冷（强制）不命中：对于空缓存的第一次不命中 缓存冲突不命中：由于缓存大小限制导致多个数据映射到同一个缓存块中发生替换造成的不命中 通用字母含义 S：缓存组数 s：缓存组占的位数 S = 2^s E：每个组的行（块）数 B：每个块的大小 b：每个块占的地址位数 B = 2^b m：内存地址最大位数 t：标记位数 t = m - (s + b) C：缓存大小 C = S * B * E 直接映射高速缓存 当E=1时我们称之为直接映射高速缓存，因为此时每个组就一行，也就是一个块，这种情况都不需要替换策略，因为每个组中只有一行，具体的缓存查询过程如下 根据一个地址我们可以得到组索引和标记 利用组索引去缓存中定位到组，再判断有效位和标记是否相同，如果都相同则命中；否则加载数据到该缓存组中 这里需要注意的是组索引的位置是在中间而不是在最前面，这样设计是有一定道理的，因为程序的局部性原理，如果组索引放到最高位上，会导致遍历数组时出现严重的冲突不命中，下面有个图来说明这个原理 组相联高速缓存 当1&lt;E&lt;S时称之为组相联高速缓存，因为此时每个组中大于1行而小于S行，具体查询步骤如下 根据一个地址我们可以得到组索引和标记 利用组索引去缓存中定位到组，再遍历组中的所有行判断有效位和标记是否相同，如果都相同则命中；否则加载数据到一个无效的行中；如果不存在无效的行，则需要执行特定的替换策略（例如：LRU）来将数据加载到缓存中 全相连高速缓存 当E=S时称之为全相连高速缓存，这时所有行都在一个组中，具体的查询步骤和组相连类似，只是不需要定位组索引，因为就一个组 总结存储器层次结构告诉我们编写代码的时候尽可能对缓存友好，特别是编写一些高性能的数学计算库一定需要考虑缓存命中率，对于极度依赖性能的程序而言缓存不命中所带来的性能损失是巨大的 然后在实际的开发过程中，我感觉有很多东西的原理是从操作系统中借鉴的，例如：使用缓存提高查询性能（时间局部性原理）、MySQL存储结构中的页（分块映射思想）等]]></content>
      <tags>
        <tag>CSAPP</tag>
        <tag>存储器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSAPP-Lab-Cache]]></title>
    <url>%2F2017%2F11%2F20%2FCSAPP-Lab-Cache%2F</url>
    <content type="text"><![CDATA[实验简介该实验由A、B两个部分组成 PartA：编写一个缓存算法模拟器，根据s E b三个参数计算出缓存命中、缓存未命中和缓存替换的次数，其中缓存替换算法使用LRU PartB：在给定的高速缓存参数s=5, E=1, b=5的条件下，优化一个矩阵转置函数，使该函数的缓存命中率满足 32 x 32： miss &lt; 300 64 x 64：miss &lt; 1300 61 x 67：miss &lt; 2000 Part-APartA部分没什么难点，主要就是缓存替换算法的实现，我这里使用一个二维数组cache[S][E]来表示缓存 cache[i][j] = -1：表示缓存无效 cache[i][j] = tag：表示该缓存块已经缓存了标记为tag的内存块 缓存替换算法我们总是保证cache[s]数组中第一个元素cache[s][0]为将要被替换的元素，具体步骤如下： 解析地址中的s和tag参数 如果cache[s]数组中未找到该标记则为未命中并且cache[s]数组中有效缓存个数小于E，则将cache[s]数组中第一个无效缓存块的值设置为tag，即cache[s][FIRST_INVALID] = tag； 如果cache[s]数组中未找到该标记，但是cache[s]数组有效缓存已满，则将cache[s]数组中第一个元素之后的所有有效块都向前移动一个单位，最后将该tag添加到末尾； 如果cache[s]数组中找到对应标记tag的位置i，则将cache[s][i]从数组中删除并追加到有效缓存块末尾 具体实现代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243#include "cachelab.h"#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#define BUFFER_SIZE 1024void printUsage()&#123; printf("Usage: ./csim-ref [-hv] -s &lt;num&gt; -E &lt;num&gt; -b &lt;num&gt; -t &lt;file&gt;\n" "Options:\n" " -h Print this help message.\n" " -v Optional verbose flag.\n" " -s &lt;num&gt; Number of set index bits.\n" " -E &lt;num&gt; Number of lines per set.\n" " -b &lt;num&gt; Number of block offset bits.\n" " -t &lt;file&gt; Trace file.\n\n" "Examples:\n" " linux&gt; ./csim-ref -s 4 -E 1 -b 4 -t traces/yi.trace\n" " linux&gt; ./csim-ref -v -s 8 -E 2 -b 4 -t traces/yi.trace\n");&#125;void move_to_tail(long array[], int len, int i)&#123; long e = array[i]; for (int j = i; j &lt; len - 1; j++) &#123; if (array[j + 1] != -1) array[j] = array[j + 1]; else &#123; array[j] = e; return; &#125; &#125; array[len - 1] = e;&#125;int add_to_cache(long array[], int len, int value)&#123; for (int i = 0; i &lt; len; i++) &#123; if (array[i] == -1) &#123; array[i] = value; return 0; &#125; &#125; move_to_tail(array, len, 0); array[len - 1] = value; return -1;&#125;unsigned long hex2long(char* hex_str, int len)&#123; unsigned long result = 0; int i; for (i = 0; i &lt; len; i++) &#123; switch (hex_str[i]) &#123; case '0': break; case '1': result |= 0x1; break; case '2': result |= 0x2; break; case '3': result |= 0x3; break; case '4': result |= 0x4; break; case '5': result |= 0x5; break; case '6': result |= 0x6; break; case '7': result |= 0x7; break; case '8': result |= 0x8; break; case '9': result |= 0x9; break; case 'a': result |= 0xa; break; case 'A': result |= 0xa; break; case 'b': result |= 0xb; break; case 'B': result |= 0xb; break; case 'c': result |= 0xc; break; case 'C': result |= 0xc; break; case 'd': result |= 0xd; break; case 'D': result |= 0xd; break; case 'e': result |= 0xe; break; case 'E': result |= 0xe; break; case 'f': result |= 0xf; break; case 'F': result |= 0xf; break; default: break; &#125; if (i != len - 1) result &lt;&lt;= 4; &#125; return result;&#125;int main(int argc, char *argv[])&#123; char* h_arg = "-h"; if (argc &lt; 2 || strcmp(argv[1], h_arg) == 0 || argc &lt; 9) &#123; printUsage(); return -1; &#125; int s, e, b; char* t; int offset = argc == 9 ? 0 : 1; int is_debug = offset; s = atoi(argv[2 + offset]); e = atoi(argv[4 + offset]); b = atoi(argv[6 + offset]); t = argv[8 + offset]; unsigned int set_num; set_num = 1 &lt;&lt; s; long cache[set_num][e]; memset(cache, -1, sizeof(cache)); char str_line[BUFFER_SIZE]; FILE *fp; if ((fp=fopen(t, "r")) == NULL) &#123; printf("%s: No such file or directory\n", t); return -1; &#125; int hits = 0, misses = 0, evictions = 0; while (!feof(fp)) &#123; if (fgets(str_line, BUFFER_SIZE, fp) == NULL) continue; if (str_line[0] != ' ') continue; int pos = strchr(str_line, ',') - str_line; unsigned long address = hex2long(str_line+3, pos - 3); unsigned long set_idx = (address &gt;&gt; b) &amp; (~(~0 &lt;&lt; s)); unsigned long tag = address &gt;&gt; (s + b); // int size = atoi(str_line + pos + 1); if (is_debug) &#123; int l = strlen(str_line); str_line[l - 1] = '\0'; printf("%s", str_line + 1); &#125; if (str_line[1] == 'L' || str_line[1] == 'S') &#123; int found = 0; for (int i = 0; i &lt; e; i++) &#123; if (cache[set_idx][i] == tag) &#123; hits++; move_to_tail(cache[set_idx], e, i); found = 1; if (is_debug) printf(" hit\n"); break; &#125; &#125; if (!found) &#123; misses++; int evi = add_to_cache(cache[set_idx], e, tag); if (evi == -1) evictions++; if (is_debug) &#123; if (evi == -1) printf(" miss eviction\n"); else printf(" miss\n"); &#125; &#125; &#125; if (str_line[1] == 'M') &#123; int found = 0; for (int i = 0; i &lt; e; i++) &#123; if (cache[set_idx][i] == tag) &#123; hits += 2; move_to_tail(cache[set_idx], e, i); found = 1; if (is_debug) printf(" hit hit\n"); break; &#125; &#125; if (!found) &#123; misses++; int evi = add_to_cache(cache[set_idx], e, tag); if (evi == -1) evictions++; hits++; if (is_debug) &#123; if (evi == -1) printf(" miss eviction hit\n"); else printf(" miss hit\n"); &#125; &#125; &#125; &#125; printSummary(hits, misses, evictions); return 0;&#125; Part-B这部分想拿满分真的挺难的，写了几个晚上才写完。。。花了大量时间思考和理解解题思路，感觉死了好多脑细胞MMP 首先我们根据缓存参数我们可以确定 缓存包含32个组，每组一行（E=1） 缓存块大小为32字节，即一个缓存块能存放8个int变量 32 x 32这里如果直接进行转置肯定是不行的，因为在32 x 32矩阵中，每行占用4个缓存块，所以8行刚好能完全储存在缓存中，但是我们的矩阵有32行，整个缓存大小不足以储存整个矩阵，所以必然存在冲突不命中 图中的数字代表缓存块标号，我们如果直接按行转置的话，第1个块的写不命中率为1（第一个块被写到B[0-7][0]） ，当我们写第2个块到B的时候，由于写冲突（第二个块需要写到B[8-15][0]，但是B[8-15][0]与之前的B[0-7][0]被映射到同一个缓存组）导致我们需要替换掉之前的缓存，这样就导致我们所有的写入操作都未命中，单单写miss次数至少为32 x 32次所以远远不满足题目要求的miss &lt; 300 参考实验指导书中的矩阵分块思想，我们这里可以将该矩阵分成8 x 8的16个小矩阵，这样每次读8个值就能充分利用缓存块，同时写的时候也可以充分利用缓存减少miss次数，图中相同颜色的区域会被映射到相同组，这里我们需要分两种情况分析 8 x 8小矩阵不包含对角线元素 不包含对角线元素在转置的时候读写不会冲突，因为他们在缓存中不会映射同一组，所以每个小矩阵的读和写的miss次数都为8次（强制不明中） 8 x 8小矩阵包含对角线元素 包含对角线元素需要考虑读写冲突，因为包含对角线的小矩阵转置时的位置不会变化，也就是原地转置，所以在处理完第一行之后，缓存中存放的是B矩阵对应的行的内容；但是当继续处理A中第二行的时候，会将已缓存的B矩阵的第二行替换掉，等到写B矩阵的时候就会多一次miss，所以这里读miss的次数为8，写miss的次数为8 + 7 很明显包含对角线的矩阵有4个，一共有16个矩阵，所以可以计算出理论miss次数为12 * (8 + 8) + 4 * (8 + 8 + 7) = 284 ，实际测试的miss值为287和我们计算的差不多 具体实现代码 123456789101112131415161718192021222324252627int t0, t1, t2, t3, t4, t5, t6, t7;for (int i = 0; i &lt; N; i += 8)&#123; for (int j = 0; j &lt; M; j += 8) &#123; for (int k = i; k &lt; i + 8; k++) &#123; t0 = A[k][j]; t1 = A[k][j + 1]; t2 = A[k][j + 2]; t3 = A[k][j + 3]; t4 = A[k][j + 4]; t5 = A[k][j + 5]; t6 = A[k][j + 6]; t7 = A[k][j + 7]; B[j][k] = t0; B[j + 1][k] = t1; B[j + 2][k] = t2; B[j + 3][k] = t3; B[j + 4][k] = t4; B[j + 5][k] = t5; B[j + 6][k] = t6; B[j + 7][k] = t7; &#125; &#125;&#125; 64 x 64这个是真的难想，我反正想不出来，最后参考了网上的解法然后自己理解+实现也花了很久。。。 第一次实验首先我们肯定是想分成8 x 8的小矩阵，但是这里不行，因为行字节数变大了导致列的冲突步长变小了，这个64 x 64的矩阵中每行需要占用8个缓存块，缓存最大只能存4行；如果我们继续按8 x 8分块，那每次写下面四行都会把上面缓存过的替换掉，导致冲突miss，粗略估算一下写miss的次数为64 * 64，崩了。。。 第二次实验那既然8 x 8不行，我们就分成4 x 4的小矩阵，好，这样分确实解决了写冲突问题，但是这样我们无法充分利用缓存，因为每个缓存块可以放8个元素，但是我们只使用4个，这里我们同样分析一下miss次数，这里需要注意的是我们不能直接按4 x 4的块进行分析，因为我们的缓存块可以存储8个元素，所以我们按4 x 8的块分析 包含对角线的块 我们可以发现包含对角线的块中，对角线可能在左边的4 x 4中，也可能在右边；这样剩下的那个4 x 4的块由于位置特殊（位于对角线块边上）在转置写入B矩阵时会存在冲突不命中，因为这个块会被写到当前块上面或者下面的4 x 8的矩阵块中，从而被映射到相同的缓存组。所以包含对角线的4 x 8中的两个块是等效的，读miss次数为4 + 4 ；写miss次数为4 + 3 + 4 + 3 不包含对角线的块 这种情况分析起来比较简单，主要注意的地方是当处理第二个4 x 4矩阵块时，由于不在对角线上所以没有冲突，并且我们缓存块可以一次读8个元素，所以第二个4 x 4的矩阵块的读miss次数为0，所以最终读miss次数为4 ；写miss次数为4 + 4 最终miss次数为16 * (4 + 4 + 4 + 3 + 4 + 3) + 112 * (4 + 4 + 4) = 1696 ，实际测试的miss次数为1699，与理论计算的次数差不多，但是我们写实验肯定是冲着满分去的，所以需要找到一种更优的解法 最终方案这里需要充分利用一次读入的8个元素，同时需要将元素暂时存放在B矩阵中，最后做调整，这里我们仍然是分成8 x 8的块，但是要分两种情况考虑，左图为矩阵A，右图为矩阵B 包含对角线的块 对于前4行，我们按行读取8个元素存入变量中，前4个元素正常转置，后面4个原地转置后存入B矩阵中 对于后4行，我们按行读取8个元素存入变量中，前4个元素原地转置存入B矩阵中，后面4个正常转置 前面两步做完后我们就得到了上面的右图也就是当前B矩阵的情况，然后观察发现我们最后只需要交换左下方和右上方的矩阵块就可以把位置调整正确，这里需要注意我们第一步操作了后面4行，所以这里为了充分利用缓存我们需要先读左下方矩阵块一行，然后读右上方一行，然后将左下方的行写到右上，再将右上行写到左下；如此往复我们就完成了一个对角线矩阵块的转置 不包含对角线的块 对于前4行，我们按行读取8个元素存入变量中，前4个元素正常转置，后面4个原地转置后存入B矩阵中 右图表示当前矩阵B的情况，对于后4行，我们可以利用非对角线块读写不冲突的性质来优化，具体做法是：对于A中后4行的左半部分，中按列读取4个元素t0 t1 t2 t3，从B的右上角按行读取4个元素t4 t5 t6 t7，然后将t0 t1 t2 t3写入B右上角的行，将t4 t5 t6 t7写入B左下角的行。这时A矩阵的右下部分和B矩阵中的右下部分已经完全载入缓存（列不同，不会发生冲突），这个时候我们处理右下角的块时缓存命中率为100% 根据上面的步骤我们来分析一下miss次数，同样分两种情况 对角线块 上半部分：读 4 写 4 + 3 下半部分：读 4 写 4 + 3 调整操作：读 1 写 1 一共4次 非对角线块 上半部分：读 4 写 4 下半部分：读 4 写 4 所以理论miss次数为56 * (4 + 4 + 4 + 4) + 8 * (4 + 4 + 3 + 4 + 4 + 3 + 8) = 1136，实际测的次数为1139次，和理论相差无几 具体实现代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586int t0, t1, t2, t3, t4, t5, t6, t7;for (int i = 0; i &lt; N; i += 8) &#123; for (int j = 0; j &lt; M; j += 8) &#123; for (int k = i; k &lt; i + 4; k++) &#123; t0 = A[k][j + 0]; t1 = A[k][j + 1]; t2 = A[k][j + 2]; t3 = A[k][j + 3]; t4 = A[k][j + 4]; t5 = A[k][j + 5]; t6 = A[k][j + 6]; t7 = A[k][j + 7]; B[j + 0][k] = t0; B[j + 1][k] = t1; B[j + 2][k] = t2; B[j + 3][k] = t3; B[j + 0][k + 4] = t4; B[j + 1][k + 4] = t5; B[j + 2][k + 4] = t6; B[j + 3][k + 4] = t7; &#125; if (i == j) &#123; for (int k = i + 4; k &lt; i + 8; k++) &#123; t0 = A[k][j + 0]; t1 = A[k][j + 1]; t2 = A[k][j + 2]; t3 = A[k][j + 3]; t4 = A[k][j + 4]; t5 = A[k][j + 5]; t6 = A[k][j + 6]; t7 = A[k][j + 7]; B[j + 4][k] = t4; B[j + 5][k] = t5; B[j + 6][k] = t6; B[j + 7][k] = t7; B[j + 4][k - 4] = t0; B[j + 5][k - 4] = t1; B[j + 6][k - 4] = t2; B[j + 7][k - 4] = t3; &#125; for (int k = i + 4; k &lt; i + 8; k++) &#123; t0 = B[k][j + 0]; t1 = B[k][j + 1]; t2 = B[k][j + 2]; t3 = B[k][j + 3]; t4 = B[k - 4][j + 4]; t5 = B[k - 4][j + 5]; t6 = B[k - 4][j + 6]; t7 = B[k - 4][j + 7]; B[k - 4][j + 4] = t0; B[k - 4][j + 5] = t1; B[k - 4][j + 6] = t2; B[k - 4][j + 7] = t3; B[k][j + 0] = t4; B[k][j + 1] = t5; B[k][j + 2] = t6; B[k][j + 3] = t7; &#125; &#125; else &#123; for (int k = j; k &lt; j + 4; k++) &#123; t0 = A[i + 4][k]; t1 = A[i + 5][k]; t2 = A[i + 6][k]; t3 = A[i + 7][k]; t4 = B[k][i + 4]; t5 = B[k][i + 5]; t6 = B[k][i + 6]; t7 = B[k][i + 7]; B[k][i + 4] = t0; B[k][i + 5] = t1; B[k][i + 6] = t2; B[k][i + 7] = t3; B[k + 4][i + 0] = t4; B[k + 4][i + 1] = t5; B[k + 4][i + 2] = t6; B[k + 4][i + 3] = t7; &#125; for (int k = j + 4; k &lt; j + 8; k++) &#123; B[k][i + 4] = A[i + 4][k]; B[k][i + 5] = A[i + 5][k]; B[k][i + 6] = A[i + 6][k]; B[k][i + 7] = A[i + 7][k]; &#125; &#125; &#125;&#125; 61 x 67这个由于是不规则的，所以可以直接用不同的分块大小测试，不像前面两个想拿满分一定要做到最优解。这里有个问题就是按列访问比按行访问miss次数少很多，我测试的按列访问并且按18 x 18分块后的miss次数是1815 具体实现代码 12345for (int i = 0; i &lt; N; i += 18) for (int j = 0; j &lt; M; j += 18) for (int dy = j; dy &lt; j + 18 &amp;&amp; dy &lt; M; dy++) for (int dx = i; dx &lt; i + 18 &amp;&amp; dx &lt; N; dx++) B[dy][dx] = A[dx][dy]; 总结这个实验花了我好多个晚上，不过写完之后对高速缓存和缓存命中率这两个概念有了比较深刻的理解 需要注意缓存冲突导致的大量不命中 需要充分利用缓存块中的数据，保持良好的空间局部性 需要尽量使用已经加载到缓存中的数据，保持良好的时间局部性 参考资料CSAPP Cache Lab Part B 深入理解计算机系统CacheLab-PartB实验报告]]></content>
      <tags>
        <tag>CSAPP</tag>
        <tag>Cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSAPP-CPU体系结构]]></title>
    <url>%2F2017%2F11%2F12%2FCSAPP-CPU%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[指令集每个CPU都有它自己的指令集（ISA），这些指令集是对CPU操作的一种抽象，这样编译器开发者只需要知道指令集而无需关具体的CPU内部实现。 Y86-64指令集结构寄存器和条件码 寄存器的定义和X86-64基本一致，只是少了一个%r15 条件码包含三个 ZF：零标志 SF：符号标志 OF：溢出标志 Stat为程序状态的定义 SAOK：正常 SADR：地址异常 SINS：非法指令 SHLT：停止状态指令集 所有的指令集都被编码成3-10个字节不等 OP操作包括：addq subq andq xorq JXX操作包括：jmp jle jl je jne jge cmovXX操作包括：cmovle cmovl cmove cmovne cmovge cmovg 这里很巧妙的将rrmoveq和cmovXX两种指令编码在一起，因为他们的功能都是数据传送，并且原操作数和目的操作数都是寄存器 寄存器抽象 把寄存器想象成一个文件，不同之处在于读写操作都由时钟控制（每次时钟从0跳变成1的时候就会触发读和写操作） 读操作：在srcX处输入寄存器标号，一段延时过后，对应的valX处的值就是对应寄存器的值 写操作：在dstW处输入寄存器标号，在valW处输入待写入的值，一段延时过后对应寄存器被赋值 指令执行过程分解将每条指令的执行过程分解成若干个步骤，并且尽量将每条指令的行为正规化有利于后续实现。这里我们可以将指令的执行分解成六个步骤 取指（fetch） 将指令从内存中取出并解析指令的格式，指令地址为程序计数器PC的值。 译码（decode） 主要是从寄存器文件中获得两个操作数的值 执行（execute） 使用算数逻辑单元ALU执行计算操作，具体的操作由opXX指令的fn字段决定 访存（memory） 执行访存操作，读取或写入内存的某个地址 写回（write-back） 将值写回寄存器文件 更新PC 将程序计数器PC的地址设置成下一条指令的地址 根据上面这六个步骤我们可以将所有指令都分解成上述六个步骤 icode：指令类型 ifun：指令的具体功能，比如区分跳转指令的类型 valA：寄存器rA对应的值 valB：寄存器rB对应的值 valE：执行阶段完成后的中间结果 valP：下一个程序计数器PC的值 Cnd：条件码，用于跳转指令的条件 现在我们将所有指令的执行过程都分解成统一的几个步骤之后，所有的准备工作都已经完成，接下来就可以开始实现一个顺序执行的Y86-64处理器了 硬件描述语言HCL简单介绍HCL语言用来描述硬件的组合逻辑，语法类似C语言，只不过最后编译生成的不是机器码而是组合逻辑电路。下面是组成该语言的基本元素 变量类型 bool int word 基本运算符 &amp;&amp; || ! == in 分支条件 1234bool x = [ a: 0 # a为true则x的值为1 b: 1 # b为true则x的值为1] Y86-64顺序实现 取指 12345678bool instr_valid = icode in &#123; INOP, IHALT, IRRMOVL, IIRMOVL, IRMMOVL, IMRMOVL, IOPL, IJXX, ICALL, IRET, IPUSHL, IPOPL &#125;;bool need_regids = icode in &#123; IRRMOVL, IOPL, IPUSHL, IPOPL, IIRMOVL, IRMMOVL, IMRMOVL &#125;;bool need_valC = icode in &#123; IIRMOVL, IRMMOVL, IMRMOVL, IJXX, ICALL &#125;; 译码和写回 123456789101112131415161718192021222324252627## What register should be used as the A source?int srcA = [ icode in &#123; IRRMOVL, IRMMOVL, IOPL, IPUSHL &#125; : rA; icode in &#123; IPOPL, IRET &#125; : RESP; 1 : RNONE; # Don't need register];## What register should be used as the B source?int srcB = [ icode in &#123; IOPL, IRMMOVL, IMRMOVL &#125; : rB; icode in &#123; IPUSHL, IPOPL, ICALL, IRET &#125; : RESP; 1 : RNONE; # Don't need register];## What register should be used as the E destination?int dstE = [ icode in &#123; IRRMOVL &#125; &amp;&amp; Cnd : rB; icode in &#123; IIRMOVL, IOPL&#125; : rB; icode in &#123; IPUSHL, IPOPL, ICALL, IRET &#125; : RESP; 1 : RNONE; # Don't write any register];## What register should be used as the M destination?int dstM = [ icode in &#123; IMRMOVL, IPOPL &#125; : rA; 1 : RNONE; # Don't write any register]; 执行 12345678910111213141516171819202122232425## Select input A to ALUint aluA = [ icode in &#123; IRRMOVL, IOPL &#125; : valA; icode in &#123; IIRMOVL, IRMMOVL, IMRMOVL &#125; : valC; icode in &#123; ICALL, IPUSHL &#125; : -4; icode in &#123; IRET, IPOPL &#125; : 4; # Other instructions don't need ALU];## Select input B to ALUint aluB = [ icode in &#123; IRMMOVL, IMRMOVL, IOPL, ICALL, IPUSHL, IRET, IPOPL &#125; : valB; icode in &#123; IRRMOVL, IIRMOVL &#125; : 0; # Other instructions don't need ALU];## Set the ALU functionint alufun = [ icode == IOPL : ifun; 1 : ALUADD;]; ## Should the condition codes be updated?bool set_cc = icode in &#123; IOPL &#125;; 访存 1234567891011121314151617181920212223242526272829## Set read control signalbool mem_read = icode in &#123; IMRMOVL, IPOPL, IRET &#125;;## Set write control signalbool mem_write = icode in &#123; IRMMOVL, IPUSHL, ICALL &#125;;## Select memory addressint mem_addr = [ icode in &#123; IRMMOVL, IPUSHL, ICALL, IMRMOVL &#125; : valE; icode in &#123; IPOPL, IRET &#125; : valA; # Other instructions don't need address];## Select memory input dataint mem_data = [ # Value from register icode in &#123; IRMMOVL, IPUSHL &#125; : valA; # Return PC icode == ICALL : valP; # Default: Don't write anything];## Determine instruction statusint Stat = [ imem_error || dmem_error : SADR; !instr_valid: SINS; icode == IHALT : SHLT; 1 : SAOK;]; 更新PC 12345678910int new_pc = [ # Call. Use instruction constant icode == ICALL : valC; # Taken branch. Use instruction constant icode == IJXX &amp;&amp; Cnd : valC; # Completion of RET instruction. Use value from stack icode == IRET : valM; # Default: Use incremented PC 1 : valP;]; SEQ总结我们将所有指令分解成一个一个的小过程，再实现所有的小过程并把它们连在一起就构成了一个顺序执行的处理器。这里所有的组合逻辑都使用HCL语言来描述，组合逻辑就像编程语言中的一个个函数，根据输入参数（信号）得到对应输出值（信号），你如果需要添加一个参数（信号）只需要在函数签名处添加参数（在逻辑门处添加一根导线）。 虽然这个顺序的Y86-64处理器能成功执行指令，但是它的速度实在是太慢了，因为它的时钟周期需要足够长来保证信号能通过所有的逻辑门。我们可以设想一条指令的执行过程，它一次通过取指、译码、执行、访存、写回和更新PC六个阶段，如果我们的时钟周期设置的不合适（过短）会导致一条指令还没执行完就执行下一条指令（下一个0-1的跳变导致寄存器触发了状态更新）。 流水线通用原理顺序实现导致效率低下的原因就是无法充分利用硬件单元，使得它长时间处于等待状态。例如：一条指令执行的时候一次经过几个阶段，当该指令经过译码阶段时，我们如果可以紧接着让下一条指令进入取指，这样就能极大提高硬件单元的利用率。 从图中我们可以发现当指令I1处于C阶段的时候，指令I2处于B阶段，指令I3处于A阶段，由于硬件单元得到了充分的利用，从而吞吐量也响应的提高了。 Y86-64流水线化 首先我们将PC更新阶段放到了最底部，然后在每个阶段之间加入必要的流水线寄存器保存中间状态，这样就顺利的把我们之前的顺序实现流水线化了，但是这里存在的问题就是一条指令需要依赖上一条指令的执行结果，例如 1234irmovq $3, %rbxirmovq $1, %raxirmovq $1, %rbxaddq %rax, %rbx 根据之前的流水线原理我们可以得出当指令addq %rax, %rbx处于译码阶段时，irmovq $1, %rbx指令处于执行阶段，这将会导致我们获取到的寄存器%rbx的值不是我们想要的1而是3，这将会导致我们指令的实际执行结果和预期不一致，这就是下面要说的流水线冒险 流水线冒险数据冒险 定义 指令无法获取到正确的值 产生场景 处理方式 针对第一种场景，我们可以使用数据转发，因为我们可以将上一条指令irmovq $3, %rax的执行阶段的值转发到译码阶段的组合逻辑中，让addq %rdx, %rax指令的译码阶段取得正确的值 针对第二种场景，我们必须使用暂停，因为当mrmovq 0(%rdx), %rax指令在访存阶段时才能获取到内存中的值，这时addq %ebx, %eax指令处于执行阶段，所以这里如果用数据转发方式我们要把这个值转发到addq %ebx, %eax的译码阶段，可是它目前处于执行阶段，所以产生了矛盾，致使我们必须将addq指令暂停在译码阶段一个周期才能顺利的取到正确的值 控制冒险 定义 处理器无法预测下一条指令的地址 产生场景 跳转指令jXX和返回指令ret 处理方式 对于跳转指令我们可以使用分支预测，例如对于跳转指令我们总是取跳转后的地址作为下一条指令的地址，等到该跳转指令处于执行阶段时我们再根据条件码来处理预测错误的情况 对于返回指令我们无法预测它的地址，所以只能采取暂停方式 Y86-64流水线实现 取指 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849## What address should instruction be fetched atint f_pc = [ # Mispredicted branch. Fetch at incremented PC M_icode == IJXX &amp;&amp; !M_Cnd : M_valA; # Completion of RET instruction. W_icode == IRET : W_valM; # Default: Use predicted value of PC 1 : F_predPC;];## Determine icode of fetched instructionint f_icode = [ imem_error : INOP; 1: imem_icode;];# Determine ifunint f_ifun = [ imem_error : FNONE; 1: imem_ifun;];# Is instruction valid?bool instr_valid = f_icode in &#123; INOP, IHALT, IRRMOVL, IIRMOVL, IRMMOVL, IMRMOVL, IOPL, IJXX, ICALL, IRET, IPUSHL, IPOPL &#125;;# Determine status code for fetched instructionint f_stat = [ imem_error: SADR; !instr_valid : SINS; f_icode == IHALT : SHLT; 1 : SAOK;];# Does fetched instruction require a regid byte?bool need_regids = f_icode in &#123; IRRMOVL, IOPL, IPUSHL, IPOPL, IIRMOVL, IRMMOVL, IMRMOVL &#125;;# Does fetched instruction require a constant word?bool need_valC = f_icode in &#123; IIRMOVL, IRMMOVL, IMRMOVL, IJXX, ICALL &#125;;# Predict next value of PCint f_predPC = [ f_icode in &#123; IJXX, ICALL &#125; : f_valC; 1 : f_valP;]; 译码和写回 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647## What register should be used as the A source?int d_srcA = [ D_icode in &#123; IRRMOVL, IRMMOVL, IOPL, IPUSHL &#125; : D_rA; D_icode in &#123; IPOPL, IRET &#125; : RESP; 1 : RNONE; # Don't need register];## What register should be used as the B source?int d_srcB = [ D_icode in &#123; IOPL, IRMMOVL, IMRMOVL &#125; : D_rB; D_icode in &#123; IPUSHL, IPOPL, ICALL, IRET &#125; : RESP; 1 : RNONE; # Don't need register];## What register should be used as the E destination?int d_dstE = [ D_icode in &#123; IRRMOVL, IIRMOVL, IOPL&#125; : D_rB; D_icode in &#123; IPUSHL, IPOPL, ICALL, IRET &#125; : RESP; 1 : RNONE; # Don't write any register];## What register should be used as the M destination?int d_dstM = [ D_icode in &#123; IMRMOVL, IPOPL &#125; : D_rA; 1 : RNONE; # Don't write any register];## What should be the A value?## Forward into decode stage for valAint d_valA = [ D_icode in &#123; ICALL, IJXX &#125; : D_valP; # Use incremented PC d_srcA == e_dstE : e_valE; # Forward valE from execute d_srcA == M_dstM : m_valM; # Forward valM from memory d_srcA == M_dstE : M_valE; # Forward valE from memory d_srcA == W_dstM : W_valM; # Forward valM from write back d_srcA == W_dstE : W_valE; # Forward valE from write back 1 : d_rvalA; # Use value read from register file];int d_valB = [ d_srcB == e_dstE : e_valE; # Forward valE from execute d_srcB == M_dstM : m_valM; # Forward valM from memory d_srcB == M_dstE : M_valE; # Forward valE from memory d_srcB == W_dstM : W_valM; # Forward valM from write back d_srcB == W_dstE : W_valE; # Forward valE from write back 1 : d_rvalB; # Use value read from register file]; 执行 123456789101112131415161718192021222324252627282930313233343536## Select input A to ALUint aluA = [ E_icode in &#123; IRRMOVL, IOPL &#125; : E_valA; E_icode in &#123; IIRMOVL, IRMMOVL, IMRMOVL &#125; : E_valC; E_icode in &#123; ICALL, IPUSHL &#125; : -4; E_icode in &#123; IRET, IPOPL &#125; : 4; # Other instructions don't need ALU];## Select input B to ALUint aluB = [ E_icode in &#123; IRMMOVL, IMRMOVL, IOPL, ICALL, IPUSHL, IRET, IPOPL &#125; : E_valB; E_icode in &#123; IRRMOVL, IIRMOVL &#125; : 0; # Other instructions don't need ALU];## Set the ALU functionint alufun = [ E_icode == IOPL : E_ifun; 1 : ALUADD;];## Should the condition codes be updated?bool set_cc = E_icode == IOPL &amp;&amp; # State changes only during normal operation !m_stat in &#123; SADR, SINS, SHLT &#125; &amp;&amp; !W_stat in &#123; SADR, SINS, SHLT &#125;;## Generate valA in execute stageint e_valA = E_valA; # Pass valA through stage## Set dstE to RNONE in event of not-taken conditional moveint e_dstE = [ E_icode == IRRMOVL &amp;&amp; !e_Cnd : RNONE; 1 : E_dstE;]; 访存 1234567891011121314151617181920212223242526272829303132333435363738## Select memory addressint mem_addr = [ M_icode in &#123; IRMMOVL, IPUSHL, ICALL, IMRMOVL &#125; : M_valE; M_icode in &#123; IPOPL, IRET &#125; : M_valA; # Other instructions don't need address];## Set read control signalbool mem_read = M_icode in &#123; IMRMOVL, IPOPL, IRET &#125;;## Set write control signalbool mem_write = M_icode in &#123; IRMMOVL, IPUSHL, ICALL &#125;;#/* $begin pipe-m_stat-hcl */## Update the statusint m_stat = [ dmem_error : SADR; 1 : M_stat;];#/* $end pipe-m_stat-hcl */## Set E port register IDint w_dstE = W_dstE;## Set E port valueint w_valE = W_valE;## Set M port register IDint w_dstM = W_dstM;## Set M port valueint w_valM = W_valM;## Update processor statusint Stat = [ W_stat == SBUB : SAOK; 1 : W_stat;]; 流水线控制逻辑 1234567891011121314151617181920212223242526272829303132333435363738394041424344# Should I stall or inject a bubble into Pipeline Register F?# At most one of these can be true.bool F_bubble = 0;bool F_stall = # Conditions for a load/use hazard E_icode in &#123; IMRMOVL, IPOPL &#125; &amp;&amp; E_dstM in &#123; d_srcA, d_srcB &#125; || # Stalling at fetch while ret passes through pipeline IRET in &#123; D_icode, E_icode, M_icode &#125;;# Should I stall or inject a bubble into Pipeline Register D?# At most one of these can be true.bool D_stall = # Conditions for a load/use hazard E_icode in &#123; IMRMOVL, IPOPL &#125; &amp;&amp; E_dstM in &#123; d_srcA, d_srcB &#125;;bool D_bubble = # Mispredicted branch (E_icode == IJXX &amp;&amp; !e_Cnd) || # Stalling at fetch while ret passes through pipeline # but not condition for a load/use hazard !(E_icode in &#123; IMRMOVL, IPOPL &#125; &amp;&amp; E_dstM in &#123; d_srcA, d_srcB &#125;) &amp;&amp; IRET in &#123; D_icode, E_icode, M_icode &#125;;# Should I stall or inject a bubble into Pipeline Register E?# At most one of these can be true.bool E_stall = 0;bool E_bubble = # Mispredicted branch (E_icode == IJXX &amp;&amp; !e_Cnd) || # Conditions for a load/use hazard E_icode in &#123; IMRMOVL, IPOPL &#125; &amp;&amp; E_dstM in &#123; d_srcA, d_srcB&#125;;# Should I stall or inject a bubble into Pipeline Register M?# At most one of these can be true.bool M_stall = 0;# Start injecting bubbles as soon as exception passes through memory stagebool M_bubble = m_stat in &#123; SADR, SINS, SHLT &#125; || W_stat in &#123; SADR, SINS, SHLT &#125;;# Should I stall or inject a bubble into Pipeline Register W?bool W_stall = W_stat in &#123; SADR, SINS, SHLT &#125;;bool W_bubble = 0; PIPE总结现代处理器都是使用流水线方式来提高性能，但是提高性能的代价就是复杂度的增加，我们必须小心的处理流水线冒险来使得处理器的执行结果和预期结果一致。这里还只是一个简单的5级流水线就有这么多情况要处理，实际的处理器流水线级数可能更多，所以可想而知其复杂程度。]]></content>
      <tags>
        <tag>CSAPP</tag>
        <tag>CPU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于补码]]></title>
    <url>%2F2017%2F10%2F31%2F%E5%85%B3%E4%BA%8E%E8%A1%A5%E7%A0%81%2F</url>
    <content type="text"><![CDATA[前言在学习计算机体系结构的时候我们知道，计算机会将负整数表示成补码形式，目的当然是为了把减法运算表示成加法运算，这样就可以复用加法运算电路了。但是在上课的时候没有深入了解一下补码运算的本质，直到最近又重新看了一遍《深入理解计算机系统》，然后对于补码以及它的运算有了更深的认识。 补码规则我们知道计算机是不能直接计算减法的，它会将负数表示成补码形式，然后执行加法运算得到最终结果。 补码的计算规则用文字表示成 \begin{equation} x_补=\left\{ \begin{aligned} 不变 & & {x >= 0}\\ 符号位不变，其余各位按位求反后加一 & & {x < 0}\\ \end{aligned} \right. \end{equation}我们来实践一下上面的规则（环境为8位二进制） -1的补码 -1的二进制表示1000 0001 按位求反得到1111 1110 加一后得到补码1111 1111 -3的补码 -3的二进制表示1000 0011 按位求反后得到1111 1100 加一后得到补码1111 1101 根据上面的实践我们得出按位求反加一运算的本质 x_反 = 10000000 + (1111111 + x)\\ x_补 = x_反 + 1 = 100000000 + x = 2^8 + x将上面的公式写成一个通式 \begin{equation} x_补=\left\{ \begin{aligned} x & & {x >= 0}\\ 2^w + x & & {x < 0}\\ \end{aligned} \right. \end{equation}\\ 其中w表示二进制位数补码运算的正确性这里我们只分析补码的加法，乘法的分析过程和加法类似 首先来看补码加法公式 (x + y)_补 = x_补 + y_补我们需要根据两个数的符号分情况讨论 均为正数两个数都为正数的情况下没什么好说的，因为正数的补码是它本身，所以上面的等式一定成立 一正一负根据补码加法公式我们可以得到 (x + y)_补 = 2^w + (x + y)\\ x_补 + y_补 = 2^w + x + y = (x + y)_补 当$x + y &gt;= 0$时，由于计算机的字长限制导致$2^w$被截断了，所以尾数部分的结果就是$x + y$，然后因为$x + y &gt; 0$，所以公式正确 当$x + y &lt; 0$时，刚好满足负数的补码规则，所以也成立 均为负数根据补码加法公式我们可以得到 (x + y)_补 = 2^w + (x + y)\\ x_补 + y_补 = 2^w + x + 2^w + y = 2^w + (2^w + x + y) $x + y &lt; 0 =&gt; 2^w + x + y &lt; 2^w$ 所以$ (2^w + x + y) $不会被截断由于计算机的字长限制导致高位被截断，所以 $2^w + (2^w + x + y) = (2^w + x + y) $故原式成立 总结保证补码运算结果正确性的根本原因就是计算机的字长限制导致高位被舍弃，其实这里可以用《深入理解计算机系统》中的一句话概括 计算机执行的“整数”运算实际上是一种模运算形式]]></content>
      <tags>
        <tag>补码</tag>
        <tag>计算机体系结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解gevent]]></title>
    <url>%2F2017%2F10%2F25%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3gevent%2F</url>
    <content type="text"><![CDATA[问题引入在使用gevent的时候发现用起来很舒服，舒服过后脑海中就产生了下面两个问题 核心调度器究竟是如何实现的？ 适用场景是什么？ 调度模型gevent调度器使用事件驱动，主协程运行事件循环不断将准备就绪的事件取出并进行上下文切换 整个运行过程的步骤如下 调度器初始化，事件列表包含两个等待调度的协程1和协程2 调度器运行协程1，当运行到阻塞操作时，切换回调度器并将阻塞事件注册到调度器 调度器运行协程2，当运行到阻塞操作时，切换回调度器并将阻塞事件注册到调度器 调度器等待事件列表中的事件就绪 调度器发现事件列表中事件1已就绪，立即切换到协程1运行，协程1运行完成后切换回调度器 调度器发现事件列表中事件2已就绪，立即切换到协程2运行，协程2运行完成后切换会调度器 调度器发现事件列表为空，溜了 调度器实现在说明调度器的实现时，要先介绍两个相关的库 greenlet greenlet实现了协程的创建和切换等操作，gevent使用的协程正是基于greenlet libev 使用C语言写的一个事件驱动框架，gevent使用的事件循环正是基于libev 先从一段简单的代码入手 1234567891011121314def f1(): print("f1 before sleep") gevent.sleep(1) print("f1 after sleep")def f2(): print("f2 before sleep") gevent.sleep(1) print("f2 after sleep")gevent.spawn(f1)gevent.spawn(f2)gevent.wait() 运行这段代码，控制台输出 1234f1 before sleepf2 before sleepf1 after sleepf2 after sleep 那么gevent.sleep函数到底做了什么，使得f1运行到sleep函数时自动切换到f2运行？ 下面是gevent.sleep函数的实现源码 12345678910# gevent.sleepdef sleep(seconds=0, ref=True): hub = get_hub() # 获取hub对象，每个线程只有一个hub对象 loop = hub.loop if seconds &lt;= 0: waiter = Waiter() loop.run_callback(waiter.switch) waiter.get() else: hub.wait(loop.timer(seconds, ref=ref)) # 核心代码 执行切换 从源码中我们发现核心函数是Hub.wait，继续查看 1234567891011# Hub.getdef wait(self, watcher): waiter = Waiter() unique = object() watcher.start(waiter.switch, unique) # 这个watcher是libev库里面的watcher start方法是将某个事件以及对应的回调函数注册到事件循环中 这里显然是将定时器事件和对应的waiter.switch方法注册到事件列表中 一旦定时器超时则马上执行该回调函数 try: result = waiter.get() if result is not unique: raise InvalidSwitchError('Invalid switch into %s: %r (expected %r)' % (getcurrent(), result, unique)) finally: watcher.stop() 一开始看到这里肯定会肯困惑，不过没关系 我们继续查看Waiter.switch和Waiter.get 12345678910111213141516171819202122232425262728# Waiter.getdef get(self): if self._exception is not _NONE: # 判断该waiter是否执行完成 if self._exception is None: return self.value else: getcurrent().throw(*self._exception) else: if self.greenlet is not None: raise ConcurrentObjectUseError('This Waiter is already used by %r' % (self.greenlet, )) self.greenlet = getcurrent() # getcurrent函数是greenlet自带的函数 获取当前代码所在的协程 try: return self.hub.switch() # 切换到hub协程中 finally: self.greenlet = None# Waiter.switchdef switch(self, value=None): greenlet = self.greenlet if greenlet is None: # 显然greenlet不为None 因为在get函数中该变量等于运行get函数的协程对象 self.value = value self._exception = None else: assert getcurrent() is self.hub, "Can only use Waiter.switch method from the Hub greenlet" switch = greenlet.switch try: switch(value) # 切换回协程 except: # pylint:disable=bare-except self.hub.handle_error(switch, *sys.exc_info()) 这里很明显hub就是gevent的核心调度器，也就是运行事件循环的地方。为了证明我们的想法，我们可以继续查看Hub.run的源码 12345678910# Hub.rundef (self): while True: loop = self.loop loop.error_handler = self try: loop.run() # 运行事件循环 libev库中的ev_loop finally: loop.error_handler = None # break the refcount cycle self.parent.throw(LoopExit('This operation would block forever', self)) 然后我们再看看gevent.spawn函数 123456789# gevent.spawndef spawn(cls, *args, **kwargs): g = cls(*args, **kwargs) # 创建Greenlet对象 g.start() # 启动Greenlet对象 return g# Greenlet.startdef start(self): if self._start_event is None: self._start_event = self.parent.loop.run_callback(self.switch) # 将该协程加入本次事件循环的就绪事件列表中 现在我们来总结一下gevent的几个核心类 Hub 核心调度器类，线程单例 负责运行事件循环并切换到各个协程中 Waiter 协程切换入口，每个协程切换的时候都需要创建一个该对象而不是显式调用switch方法 每个协程切换前都需要执行下面三个步骤 创建Waiter对象waiter 将waiter.switch与事件对应的回调函数绑定 执行waiter.get函数完成切换（切换到hub中） Watcher 对应libev中的watcher 封装所有事件，每类事件都用对应的Watcher对象，Watcher.start方法将事件以及对应的回调函数注册到事件循环中 socket示例我们知道gevent是把所有可能阻塞的操作都替换成自己写的函数，从而能在修改少量代码的基础上无缝切换 下面我们来看下gevent库提供的socket.recv函数 1234567891011121314151617181920212223# socket.recvdef recv(self, *args): while True: try: return _socket.socket.recv(self._sock, *args) # 运行原生的socket.recv函数 此时的socket运行在非阻塞模式 except error as ex: # 处理非阻塞异常 if ex.args[0] != EWOULDBLOCK or self.timeout == 0.0: raise self._wait(self._read_event) # 这里又是一个_wait方法，执行协程切换# socket._waitdef _wait(self, watcher, timeout_exc=timeout('timed out')): if watcher.callback is not None: raise _socketcommon.ConcurrentObjectUseError('This socket is already used by another greenlet: %r' % (watcher.callback, )) if self.timeout is not None: timeout = Timeout.start_new(self.timeout, timeout_exc, ref=False) else: timeout = None try: self.hub.wait(watcher) # 调用wait方法将事件和回调函数注册到事件循环中并切换到hub中 这个watcher就是上面传进来的self._read_event（socket可读事件） finally: if timeout is not None: timeout.cancel() 适用场景通过分析gevent的实现，我们可以总结出它非常适用于I/O密集型的高并发应用，例如WEB服务器和处理大量连接的TCP服务端；不适用于CPU密集型应用（协程切换开销）]]></content>
      <tags>
        <tag>gevent</tag>
        <tag>协程</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB-WiredTiger存储引擎]]></title>
    <url>%2F2017%2F10%2F17%2FMongoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[前言MongoDB 3.2版本之后都默认使用该存储引擎 特点文档级并行 写操作加锁的粒度是文档级别，可以极大提高插入性能 仍然存在一些操作需要锁库锁集合，例如删除集合操作等 MVCC和Checkpoints WiredTiger存储引擎使用MVCC（多版本并发控制）达到类似读写分离的效果并且针对读多写少的场景能极大提高并发性能 WiredTiger将所有内中中的快照写入到磁盘作为检查点，默认每隔60秒或操作日志达到2GB时将创建一个新的检查点（存档点）以便于发生意外情况时能迅速利用检查点和日志进行数据恢复 新的检查点创建完成之后旧的检查点不会被立即清除，直到新的检查点可访问并已经持久化完毕（完全创建完成） WAL 将两个检查点之间的所有操作记录到WAL中 默认使用snappy压缩日志文件，压缩的最小粒度是128字节，小于128字节的日志不会被压缩 默认50ms将内存缓冲区中的WAL刷到磁盘中，可以在写请求中指定参数使该请求强制刷到磁盘中 日志文件粒度是100MB，如果大于100M则会被分成多个日志文件 数据压缩 WiredTiger会压缩所有的集合和索引数据 默认使用snappy压缩集合数据，前缀压缩索引数据 对于大多数使用场景，使用默认的数据压缩选项即可 内存使用 内存下限是 256MB 内存上限是 [RAM]/2 - 1G 操作系统参数 禁用NUMA 使用xfs文件系统较于ext4性能更好并且可以避免出现性能问题 关闭THP 禁用SELinux 将readahead设为0]]></content>
      <tags>
        <tag>MongoDB</tag>
        <tag>WiredTiger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git正确使用姿势]]></title>
    <url>%2F2017%2F10%2F15%2FGit%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8%E5%A7%BF%E5%8A%BF%2F</url>
    <content type="text"><![CDATA[为什么需要规范Git的使用 大大降低项目维护成本 方便做代码review 提高测试人员的测试效率 分支master 主分支，所有直接面向用户的版本都在这个分支上发布 dev 日常开发使用的分支 临时分支 功能（feature-*） 增加新功能而使用的分支，从dev分支分出，最后合并到dev分支 预发布（release-*） 发布正式版本之前的测试版本，结束后需要合并进dev和master分支 修复bug（fixbug-*） 从master分支上分出，修复完成后需要合并到master分支 上述三种临时分支使用完成后都需要删除以便确保仓库内始终只有master和dev两个分支 流程 新建分支 在分支上做开发 提交修改 新分支同步master分支(pull from master) 合并commit(rebase) 推送到远程仓库(push) 合并新分支到master(pull request) 删除新创建的分支 提交信息主题 A：添加 U：更新 D：删除 F：修复已知错误 B：BUG修复，需要带上BUGID R：重构 详细描述（选填）当你修改的内容无法用一句话描述时，就可以加上详细描述。详细描述主要说明以下两点 为什么需要修改 如何解决问题 影响（选填） 此次修改引发的副作用 可能影响到的模块 测试建议 此次的改动该如何测试 测试需要注意的地方 具体格式123456789主题[详细描述]* 影响1* 影响2[测试建议] 注意 每个类别之间空一行 测试建议前面空两行 示例123456789[A]添加JSON校验模块对每个请求的JSON进行字段校验来保证数据正确性* 校验失败后不会继续处理请求直接返回错误信息1.发送正确请求数据，服务器能正常返回2.发送错误请求数据（JSON格式错误），服务器返回JSON格式校验失败，并携带错误的具体信息 12345678[B]修复用户无法注册问题 #1122由于数据库连接配置错误导致无法连接数据库从而导致用户注册功能失效1.正常注册用户，服务器返回成功2.使用新注册的用户能成功登陆系统 参考资料Git 使用规范流程 Git 分支管理策略 Git 写出好的 commit message]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB-索引]]></title>
    <url>%2F2017%2F10%2F13%2FMongoDB%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[类型单一字段索引 针对单个字段建立的索引 索引顺序不会影响排序速度 多字段索引 针对2个或以上字段建立的索引 索引顺序至关重要（会影响查询和排序操作） 查询条件和排序操作需要注意： 例如：createIndex( { “a”: 1, “b”: 1, “c”: 1 } ) 查询操作只有在查询{“a”: “”}, {“a”: “”, “b”: “”}, {“a”: “”, “b”: “”, “c”: “”}三种情况下才会利用索引 排序操作只有在针对{ “a”: 1, “b”: 1, “c”: 1 }和{ “a”: -1, “b”: -1, “c”: -1 }两种情况下会使用索引，其他例如{ “a”: -1, “b”: 1, “c”: 1 }的情况下无法利用索引 数组索引 创建字段索引时如果该字段是数组，则MongoDB会自动为数组中的所有元素创建索引 创建多字段索引时最多只能包含一个数组类型的字段 建立索引时间较长 文本索引 针对文本内容搜索 每个集合最多创建一个文本索引，但是该索引可为复合索引（多个key） 可以为索引中的每个key添加一个权重，查询操作会依赖该权重对结果进行调整 排序时无法利用文本索引 建立大文本索引时需要确保你能打开足够多的文件描述符fd 对插入性能有影响 无局部性特征（某个单词周围的单词可能不会都在内存中） 默认为稀疏索引 2D球面索引（空间索引） 经纬度索引，用于空间位置查询（空间查询必须要建立索引） 默认稀疏索引 无法作为分片KEY 选项唯一 字段具有唯一性，如果字段不具有唯一性则创建该索引会报错 稀疏（推荐用部分索引） 建立索引时忽略值为null或者字段不存在的记录 适用于索引字段为null并且数据量很多的场景 忽略大小写 针对string类型 忽略大小写进行比较，可以自定义比较函数和语言 适用于大小写不敏感的场景，该选项能提高查询性能 部分索引 创建索引时指定条件，只有满足条件的数据才会建立索引 查询时条件需要是创建索引条件的子集才能利用索引 适用于数据数量很多并且只有部分数据需要经常查询的场景 TTL索引 指定一个字段作为超时时间，到期自动删除记录 文档中如果该字段不存在则永远不会被删除 适用于短时间内需要保存的数据，例如：会话 后台创建 创建索引使用异步方式执行 适用于集合数据量特别大的情况]]></content>
      <tags>
        <tag>MongoDB</tag>
        <tag>index</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库相关]]></title>
    <url>%2F2017%2F10%2F10%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[存储方式几张图看懂列式存储 事务概念对数据库的一系列操作，这些操作要么全都执行，要么全都不执行 特点 原子性（A）：事务中的操作要么全都执行要么全都不执行 一致性（C）：事务完成后需要使所有数据保持一致的状态 隔离性（I）：多个事务需要进行隔离 持久性（D）：事务的一系列操作对系统的影响是持久性的 术语说明 脏读 A事务可读取其他事务中未提交的数据 不可重复读 A事务范围内的两次查询返回的结果集不一致 幻读 A事务范围内的操作（查询-更新或删除-查询）返回的结果集不一致 隔离级别 Read uncommitted A事务可以读取B事务中未提交的数据，可能会出现脏读 Read committed A事务必须等待B事务提交后才可读数据，可能出现不可重复读 Repeatable read 当A事务开启时，B事务更新了数据并提交，但在A事务范围内无法看到数据更新，即可重复读。但该隔离级别可能出现幻读现象 Serializable 顺序执行每个事务，事务的最高隔离级别，可以避免脏读，不可重复读和幻读]]></content>
      <tags>
        <tag>DB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scala函数式编程-错误处理]]></title>
    <url>%2F2017%2F09%2F26%2FScala%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B-%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[为什么不使用异常处理错误 破坏引用透明 函数式编程的特点之一就是引用透明，所有表达式都能本地推导（locally），不依赖上下文；而throw表达式则需要依赖try代码块等上下文，不满足引用透明。 对高阶函数不友好 函数式编程的核心之一就是函数的组合，但是在高阶函数中我们无法根据一个函数的签名来预知该函数可能产生哪些异常。例如 1def map[A, B](as: List[A])(f: A =&gt; B): List[B] 我们无法根据f: A =&gt; B来预知它会产生什么异常从而无法优雅的使用map等高阶函数 Option类型函数式编程使用类型来解决错误处理，将数据包裹在一个容器里面，这个容器可能有数据也可能没有，使用子类代表有和没有的情况，所以我们引入一种新的类型Option，他的定义看起来应该是这样的 123trait Option[+A]case class Some[A](value: A) extends Option[A]case object None extends Option[Nothing] 1234567// 异常版本def mean(l: Seq[Double]): Double = if (l.isEmpty) throw new Error("sum empty list") else l.sum / l.length// 使用我们的新类型Optiondef mean(l: Seq[Double]): Option[Double] = if (l.isEmpty) None else Some(l.sum / l.length) 所以我们可以使用一个Option类型来把结果包装进去，使得我们的函数满足引用透明并且不失去组合型 直观的使用方式虽然我们引入了一个新的类型，但是我们尝试使用这个类型作为返回值的时候发现了一个问题 123456789101112131415161718def parseInt(s: String): Option[Int]def addOne(s: String): Option[String] = &#123; parseInt(s) match &#123; case Some(x) =&gt; Some((x + 1).toString()) case None =&gt; None &#125;&#125;def add(s1: String, s2: String): Option[Int] = &#123; val int1 = parseInt(s1) val int2 = parseInt(s2) int1 match &#123; case Some(x) =&gt; int2 match &#123; case Some(y) =&gt; Some(x + y) case None =&gt; None &#125; case None =&gt; None &#125;&#125; 这里我们还只有两层嵌套，如果有多层嵌套那不是要写无数个match表达式？？？ 一般到了这一步我们就应该思考如何将这种直观的使用方式抽象成高阶函数 抽象成一般模式这里我们可以模仿List类抽象出map和flatMap两个高阶函数来描述上面两个函数的模式。 mapaddOne函数是将一个String对象转化成Int并且执行加法操作后在转化成String对象，这里我们可以描述成一个一般过程 首先判断该容器是否为None 如果是直接返回None，否则将该数据取出并且执行某个转化操作之后将数据重新放入Option中 所以我们得到了map函数的定义 123trait Option[A] &#123; def map[B](f: A =&gt; B): Option[B]&#125; flatMapadd函数是将两个String表示的整数相加并且将结果包装到Option类型中，这里我们可以将这个步骤泛化成一般步骤 首先判断该容器是否为None 如果是直接返回None，否则将该数据取出并且执行某个转化操作将其转化成另外一个容器 所以我们得到了flatMap函数的定义 123trait Option[A] &#123; def flatMap[B](f: A =&gt; Option[B]): Option[B]&#125; 使用一般模式重构现在我们有了两个高阶函数map和flatMap，接下来我们可以使用这两个高阶函数来表达我们之前的addOne和add函数 1234def addOne(s: String): Option[String] = parseInt(s).map((_ + 1).toString())def add(s1: String, s2: String): Option[Int] = parseInt(s1).flatMap &#123;x =&gt; parseInt(s2).map(y =&gt; x + y)&#125; 这个add函数好像看起来仍然很复杂，不过没关系，我们可以使用scala给我们提供的一种语法糖来更加清晰的表达这个过程 1234def add(s1: String, s2: String): Option[Int] = for &#123; x &lt;- parseInt(s1) y &lt;- parseInt(s2)&#125; yield x + y 现在重构过的addOne和add函数结构清晰并且可读性大大提高，这才是我们最终的目的 Either类型在我们需要包含错误的具体信息的时候，Option类型就不能满足我们的需求，很明显它在错误时不能提供具体的错误信息，所以我们需要一个更加通用的类型来满足这个使用场景 123trait Either[+E, +A]case class Left[E](value: E) extends Either[E, Nothing]case class Right[A](value: A) extends Either[Nothing, A] 这个类型个Option类似，只不过将None替换成了一个包含具体信息的类型Left，同理也可以为它定义map和flatMap等高阶函数来操作它，这里我们不做赘述 总结函数式编程的错误处理是使用一个新的数据类型代替异常机制，并且针对该类型的日常使用方式抽象出通用的高阶函数来操作这个新的数据类型，最终目的是为了满足函数式编程的特性]]></content>
      <tags>
        <tag>Scala</tag>
        <tag>FP</tag>
        <tag>Option</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rancher网络浅析]]></title>
    <url>%2F2017%2F09%2F20%2FRancher%E7%BD%91%E7%BB%9C%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言Rancher是一个容器管理平台，默认提供了一个覆盖网络（overlay）来支持一容器一IP，并且使用IPSEC隧道来支持跨宿主机访问容器。还可以对容器进行分组隔离、标签隔离等各种粒度的隔离控制，由于工作需要就去了解了一下它具体是如何实现这些功能的。 组件说明Rancher默认的网络主要有这四个容器，他们的作用如下： rancher/net:holder IPSEC隧道封包拆包 rancher/net IPSEC隧道CNI驱动和隧道路由 rancher/network-policy-manager 管理iptables rancher/network-manager 集群节点数据同步 原理安全策略使用iptables的forward链来限制转发策略 iptables 的forward链匹配10.10.42.0/16的源地址和目的地址 如果匹配成功则匹配自定义规则链（自定义安全策略全都在forward链中） 如果匹配失败则允许转发（安全策略无法限制宿主机访问容器） 跨宿主机访问使用IPSEC隧道模式来支持容器跨宿主机访问，所有跨主机数据包默认加密 IP隧道IP隧道就是将数据封装到一个自定义的协议中，然后通过TCP或UDP传输到目标主机，目标主机再进行拆包得到真实报文并进行后续处理。理论上只需要满足IP层可达就可以使用IP隧道。 封包过程 arp代理拦截ARP请求报文并判断请求IP地址是否处于同一宿主机 如果处于同一宿主机则不操作，实际的IP地址对应的MAC地址为真实地址（docker0网桥中已经连接的某个容器的MAC） 如果处于其他宿主机（跨主机），则响应IP地址对应的MAC地址为IPSEC容器的MAC地址。由于网桥相当于数据链路层使用MAC地址，所以这里会把数据包转发到IPSEC容器内部，之后该容器使用IPSEC协议将数据包封装成UDP包并发送到目标宿主机的500端口 拆包过程 iptables的prerouting链匹配UDP协议并且目的端口号为500的数据包，将目的地址修改成宿主机IPSEC容器IP地址 IPSEC容器拆包并将数据包转发到真实容器 总结 对于吞吐量敏感的场景应该关闭加密数据包以便获得更大的吞吐量 不在rancher网络体系下的机器不受安全策略影响 理论上只要IP可达就能支持跨宿主机通信]]></content>
      <tags>
        <tag>Rancher</tag>
        <tag>iptables</tag>
        <tag>IP隧道</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM-内存模型与内存溢出分析]]></title>
    <url>%2F2017%2F09%2F12%2FJVM-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[JVM内存模型 堆区 堆区主要存放使用关键字new创建的对象和数组 堆区被所有线程共享 垃圾收集的主要目标 空间上只需要逻辑连续，物理上可以不连续 栈区栈区分为两个部分 本地方法栈 虚拟机栈 虚拟机方法栈 存储Java方法调用时产生的局部变量等信息，每个方法调用时都会创建一个栈帧（frame） 线程私有，每个线程都有属于自己的方法栈 本地方法栈 存储非Java方法调用产生的局部变量等信息 类似普通方法栈 方法区方法区主要分为三个部分 类信息 静态变量 运行时常量 程序计数器 指向当前线程正在执行的字节码指令地址 内存空间较小 线程私有（每个线程都有自己的程序计数器） 内存溢出分析在了解了JVM的内存模型之后，我们就可以根据该模型来分析各种内存溢出的可能原因。 在JAVA程序中基本上很少显示操作程序计数器区域，所以该区域一般不会发生内存溢出。故JVM中可能发生内存溢出的区域主要有三个区域：堆区、栈区、方法区。 堆溢出场景12java.lang.OutOfMemoryError: Java heap space... 原因 程序运行时所需对象的总大小大于堆内存的最大值 解决方案 首先需要使用一些性能分析工具来确定是内存溢出（overflow）还是内存泄漏（leak） 如果是内存溢出则说明程序确实需要这么大的堆内存，我们可以通过调整参数-Xms和-Xmx 来增大堆内存 如果是内存泄漏则需要工具确定泄漏内存的代码位置从而修复内存泄漏问题 栈溢出场景12java.lang.StackOverflow... 原因 线程栈超出虚拟机所允许的最大深度，例如递归调用 线程执行方法调用时没有足够的栈空间创建新的栈帧 解决方案 一般根据该异常可直接定位到具体的代码位置，并且该异常绝大多数是由于不正确的递归调用导致 通过参数 -Xss 来调整栈容量 方法区溢出场景12java.lang.OutOfMemoryError: PermGen space... 原因 运行时大量生成Class，例如使用JDK动态代理和CGLib等字节码生成工具 显式调用了Strin.intern()方法将常量扔进常量池 解决方案 根据异常定位到具体代码位置，分析代码逻辑 通过-XX:PermSize=64M -XX:MaxPermSize=128M来调整方法区大小 本机直接内存溢出在JVM中有些特殊方法可能直接使用本机内存，例如：NIO方法 这部分内存虽然不受JVM内存限制但受本机最大内存限制，直接内存可以通过参数-XX:MaxDirectMemorySize指定并且默认大小等于堆内存大小。由于这部分内存频繁使用，所以也可能出现内存溢出。 场景12java.lang.OutOfMemoryError... 原因 使用了NIO方法并且内存设置不当（JVM内存+直接内存&gt;=物理内存） 解决方案 根据异常定位代码位置，分析代码逻辑 调整内存分配（JVM内存+直接内存&lt;=物理内存）]]></content>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scala函数式编程-递归数据结构]]></title>
    <url>%2F2017%2F09%2F07%2FScala%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B-%E9%80%92%E5%BD%92%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[递归定义列表对于任意一个列表[1, 2, 3…]，它可以看成由头元素和剩下的列表组成 在Scala标准库中的List是一种类似单向链表的结构 例如：12List(1, 2, 3) = 1 :: (2 :: (3 :: Nil))List(1) = 1 :: Nil 常用函数递归实现求和函数对于递归定义的列表，求所有元素的总和可以表达成下面的递归式： sum(lst) = head(lst) + sum(tail(lst)) 将上面的递归式转化成Scala中的代码1234def sum(lst: List[Int]): Int = lst match &#123; case head :: tail =&gt; head + sum(tail) case _ =&gt; 0&#125; 求乘积1234def multi(lst: List[Int]): Int = lst match &#123; case head :: tail =&gt; head * sum(tail) case _ =&gt; 1&#125; 统计某个元素出现次数1234def count[A](lst: List[A], a: A): Int = lst match &#123; case head :: tail =&gt; if (head == a) 1 + count(tail, a) else count(tail, a) case _ =&gt; 0&#125; 抽象成一般模式通过观察上面的几个常用函数的实现模式，我们可以发现每个函数的整体结构类似，不同之处在于 对于空列表的返回值 对每个元素的处理方式 所以我们可以将上述模式抽象成一个更加通用的高阶函数，这个函数需要下面几个参数 列表为空时返回的初始值 将列表元素与累加器合并的函数 下面给出这个函数的实现1234def foldRight[A, B](lst: List[A], z: B)(f : (A, B) =&gt; B): B = lst match &#123; case x :: xs =&gt; f(x, foldRight(xs, z)(f)) case _ =&gt; z&#125; 利用这个foldRight我们可以重构上面三个函数 123456789def sum(lst: List[Int]): Int = foldRight(lst, 0)((x, acc) =&gt; x + acc)// _ * _ 等价于 (a, b) =&gt; (a * b)def multi(lst: List[Int]): Int = foldRight(lst, 1)(_ * _)def count[A](lst: List[A], a: A): Int = foldRight(lst, 0)((x, acc) =&gt; if (x == a) 1 + acc else acc) Cool！]]></content>
      <tags>
        <tag>Scala</tag>
        <tag>FP</tag>
        <tag>List</tag>
      </tags>
  </entry>
</search>
